{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Coax Cartpole A2C Replication.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMMfO5ys+yBb4eLR//RICEF"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_i5sdhYJE5sl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DpUEEsq40xC"
      },
      "outputs": [],
      "source": [
        "!pip install -U dm-haiku\n",
        "!pip install optax\n",
        "\n",
        "!pip install gym==0.24.0\n",
        "!pip install gym[classic_control]\n",
        "\n",
        "!pip install coax"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import coax\n",
        "import gym\n",
        "import haiku as hk\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import optax\n",
        "from coax.value_losses import mse, huber\n",
        "\n",
        "import numpy as onp"
      ],
      "metadata": {
        "id": "8Ema6Y4745OB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the name of this script\n",
        "name = 'a2c'\n",
        "\n",
        "# the cart-pole MDP\n",
        "env = gym.make('CartPole-v0')\n",
        "env = coax.wrappers.TrainMonitor(env, name=name, tensorboard_dir=f\"./data/tensorboard_custom/{name}\")"
      ],
      "metadata": {
        "id": "UgBqGvfg47nD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def func_pi(S, is_training):\n",
        "    logits = hk.Sequential((\n",
        "        hk.Linear(8), jax.nn.relu,\n",
        "        hk.Linear(8), jax.nn.relu,\n",
        "        hk.Linear(8), jax.nn.relu,\n",
        "        hk.Linear(env.action_space.n, w_init=jnp.zeros)\n",
        "    ))\n",
        "    return {'logits': logits(S)}\n",
        "\n",
        "\n",
        "# def func_v(S, is_training):\n",
        "#     value = hk.Sequential((\n",
        "#         hk.Linear(8), jax.nn.relu,\n",
        "#         hk.Linear(8), jax.nn.relu,\n",
        "#         hk.Linear(8), jax.nn.relu,\n",
        "#         hk.Linear(1, w_init=jnp.zeros), jnp.ravel\n",
        "#     ))\n",
        "#     return value(S)"
      ],
      "metadata": {
        "id": "nQiBS_2Z6Cyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# these optimizers collect batches of grads before applying updates\n",
        "optimizer_v = optax.chain(optax.apply_every(k=32), optax.adam(0.002))\n",
        "optimizer_pi = optax.chain(optax.apply_every(k=32), optax.adam(0.001))"
      ],
      "metadata": {
        "id": "HMIVj67s_yFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "502AJ5XqPGj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# experience tracer\n",
        "tracer = coax.reward_tracing.NStep(n=1, gamma=0.9)"
      ],
      "metadata": {
        "id": "cDcbcgzKPGRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GdA1MiQiPGBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pi = coax.Policy(func_pi, env)"
      ],
      "metadata": {
        "id": "N5xx42D4_00P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-OPbt0GR_5Mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomStateMixin:\n",
        "    @property\n",
        "    def random_seed(self):\n",
        "        return self._random_seed\n",
        "\n",
        "    @random_seed.setter\n",
        "    def random_seed(self, new_random_seed):\n",
        "        if new_random_seed is None:\n",
        "            new_random_seed = onp.random.randint(2147483647)\n",
        "        self._random_seed = new_random_seed\n",
        "        self._random_key = jax.random.PRNGKey(self._random_seed)\n",
        "\n",
        "    @property\n",
        "    def rng(self):\n",
        "        self._random_key, key = jax.random.split(self._random_key)\n",
        "        return key"
      ],
      "metadata": {
        "id": "FOxPQql1AX_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "s5Izj4IrJ1D7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomV(RandomStateMixin):\n",
        "    def __init__(self, env, random_seed=None):\n",
        "        self.random_seed = random_seed  # also initializes self.rng via RandomStateMixin\n",
        "        self._jitted_funcs = {}\n",
        "        self._space = env.observation_space\n",
        "\n",
        "        def func_v(S):\n",
        "            value = hk.Sequential((\n",
        "            hk.Linear(8), jax.nn.relu,\n",
        "            hk.Linear(8), jax.nn.relu,\n",
        "            hk.Linear(8), jax.nn.relu,\n",
        "            hk.Linear(1, w_init=jnp.zeros), jnp.ravel))\n",
        "            return value(S)\n",
        "        \n",
        "        # Haiku-transform the provided func\n",
        "        transformed = hk.transform_with_state(func_v)\n",
        "        self._function = jax.jit(transformed.apply)\n",
        "\n",
        "        # init function params and state\n",
        "        dummy = self._space.sample() \n",
        "        dummy = self.observation_preprocessor(dummy)\n",
        "        self._params, self._function_state = transformed.init(self.rng, dummy)\n",
        "\n",
        "        def soft_update_func(old, new, tau):\n",
        "            return jax.tree_map(lambda a, b: (1 - tau) * a + tau * b, old, new)\n",
        "\n",
        "        self._soft_update_func = jax.jit(soft_update_func)\n",
        "\n",
        "    def __call__(self, s):\n",
        "        S = self.observation_preprocessor(s)\n",
        "        V, _ = self.function(self.params, self.function_state, self.rng, S)\n",
        "        return onp.asarray(V[0])\n",
        "\n",
        "    def observation_preprocessor(self, X):\n",
        "        X = jnp.asarray(X, dtype=self._space.dtype)   # ensure ndarray\n",
        "        X = jnp.reshape(X, (-1, *self._space.shape))  # ensure batch axis\n",
        "        X = jnp.clip(X, self._space.low, self._space.high)  # clip to be safe\n",
        "        return X\n",
        "\n",
        "    @property\n",
        "    def params(self):\n",
        "        return self._params\n",
        "\n",
        "    @params.setter\n",
        "    def params(self, new_params):\n",
        "        if jax.tree_structure(new_params) != jax.tree_structure(self._params):\n",
        "            raise TypeError(\"new params must have the same structure as old params\")\n",
        "        self._params = new_params\n",
        "\n",
        "    @property\n",
        "    def function(self):\n",
        "        \"\"\"\n",
        "        This function may be called directly as:\n",
        "        output, function_state = obj.function(obj.params, obj.function_state, obj.rng, *inputs)\n",
        "        \"\"\"\n",
        "        return self._function\n",
        "\n",
        "    @property\n",
        "    def function_state(self):\n",
        "        return self._function_state\n",
        "\n",
        "    @function_state.setter\n",
        "    def function_state(self, new_function_state):\n",
        "        if jax.tree_structure(new_function_state) != jax.tree_structure(self._function_state):\n",
        "            raise TypeError(\"new function_state must have the same structure as old function_state\")\n",
        "        self._function_state = new_function_state\n",
        "\n",
        "    def soft_update(self, other, tau):\n",
        "        self.params = self._soft_update_func(self.params, other.params, tau)\n",
        "        self.function_state = self._soft_update_func(self.function_state, other.function_state, tau)"
      ],
      "metadata": {
        "id": "FQ88o-D-BPR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v = CustomV(env)"
      ],
      "metadata": {
        "id": "IJwQsBJqQhlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "A3ojbsAgQhUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTDLearning:\n",
        "    def __init__(self, v, loss_function, optimizer):\n",
        "        self._f = v\n",
        "        self._f_targ = v\n",
        "        self.loss_function = huber if loss_function is None else loss_function\n",
        "\n",
        "        # optimizer\n",
        "        self._optimizer = optax.adam(1e-3) if optimizer is None else optimizer\n",
        "        self._optimizer_state = self.optimizer.init(self._f.params)\n",
        "\n",
        "        def loss_func(params, target_params, state, target_state, rng, transition_batch):\n",
        "            rngs = hk.PRNGSequence(rng)\n",
        "            S = self.v.observation_preprocessor(transition_batch.S)\n",
        "            W = jnp.clip(transition_batch.W, 0.1, 10.)  # clip importance weights to reduce variance\n",
        "\n",
        "            metrics = {}\n",
        "\n",
        "            V, state_new = self.v.function(params, state, next(rngs), S)\n",
        "            G = self.target_func(target_params, target_state, next(rngs), transition_batch)\n",
        "            loss = self.loss_function(G, V, W)\n",
        "\n",
        "            # only needed for metrics dict\n",
        "            V_targ, _ = self.v.function(\n",
        "                target_params['v_targ'], target_state['v_targ'], next(rngs), S)\n",
        "\n",
        "            dLoss_dV = jax.grad(self.loss_function, argnums=1)\n",
        "            td_error = -V.shape[0] * dLoss_dV(G, V)  # e.g. (G - V) if loss function is MSE\n",
        "            metrics.update({\n",
        "                f'{self.__class__.__name__}/loss': loss,\n",
        "                f'{self.__class__.__name__}/td_error': jnp.mean(W * td_error),\n",
        "                f'{self.__class__.__name__}/td_error_targ': jnp.mean(-dLoss_dV(V, V_targ, W)),\n",
        "            })\n",
        "            return loss, (td_error, state_new, metrics)\n",
        "\n",
        "        def apply_grads_func(opt, opt_state, params, grads):\n",
        "            updates, new_opt_state = opt.update(grads, opt_state, params)\n",
        "            new_params = optax.apply_updates(params, updates)\n",
        "            return new_opt_state, new_params\n",
        "\n",
        "        self._apply_grads_func = jax.jit(apply_grads_func, static_argnums=0)  \n",
        "\n",
        "        def grads_and_metrics_func(\n",
        "                params, target_params, state, target_state, rng, transition_batch):\n",
        "\n",
        "            rngs = hk.PRNGSequence(rng)\n",
        "            grads, (td_error, state_new, metrics) = jax.grad(loss_func, has_aux=True)(\n",
        "                params, target_params, state, target_state, next(rngs), transition_batch)\n",
        "            \n",
        "            def _get_leaf_diagnostics(leaf, key_prefix):\n",
        "                # update this to add more grads diagnostics\n",
        "                return {\n",
        "                    f'{key_prefix}max': jnp.max(jnp.abs(leaf)),\n",
        "                    f'{key_prefix}norm': jnp.linalg.norm(jnp.ravel(leaf)),\n",
        "                }\n",
        "\n",
        "            def tree_ravel(pytree):\n",
        "                return jnp.concatenate([jnp.ravel(leaf) for leaf in jax.tree_leaves(pytree)])\n",
        "\n",
        "            def get_grads_diagnostics(grads, key_prefix=''):\n",
        "                return _get_leaf_diagnostics(tree_ravel(grads), key_prefix)\n",
        "\n",
        "            # add some diagnostics about the gradients\n",
        "            metrics.update(get_grads_diagnostics(grads, f'{self.__class__.__name__}/grads_'))\n",
        "\n",
        "            return grads, state_new, metrics, td_error\n",
        "\n",
        "        self._grads_and_metrics_func = jax.jit(grads_and_metrics_func)\n",
        "\n",
        "    def target_func(self, target_params, target_state, rng, transition_batch):\n",
        "        rngs = hk.PRNGSequence(rng)\n",
        "        params, state = target_params['v_targ'], target_state['v_targ']\n",
        "        S_next = self.v_targ.observation_preprocessor(transition_batch.S_next)\n",
        "\n",
        "        V_next, _ = self.v_targ.function(params, state, next(rngs), S_next)\n",
        "        return transition_batch.Rn + transition_batch.In * V_next\n",
        "\n",
        "    def update(self, transition_batch, return_td_error=False):\n",
        "        grads, function_state, metrics, td_error = self.grads_and_metrics(transition_batch)\n",
        "        if any(jnp.any(jnp.isnan(g)) for g in jax.tree_leaves(grads)):\n",
        "            raise RuntimeError(f\"found nan's in grads: {grads}\")\n",
        "        self.apply_grads(grads, function_state)\n",
        "        return (metrics, td_error) if return_td_error else metrics   \n",
        "\n",
        "    def apply_grads(self, grads, function_state):\n",
        "        self._f.function_state = function_state\n",
        "        self.optimizer_state, self._f.params = \\\n",
        "            self._apply_grads_func(self.optimizer, self.optimizer_state, self._f.params, grads)   \n",
        "\n",
        "    def grads_and_metrics(self, transition_batch):\n",
        "        return self._grads_and_metrics_func(\n",
        "            self._f.params, self.target_params, self._f.function_state, self.target_function_state,\n",
        "            self._f.rng, transition_batch)\n",
        "        \n",
        "    @property\n",
        "    def optimizer(self):\n",
        "        return self._optimizer\n",
        "\n",
        "    @optimizer.setter\n",
        "    def optimizer(self, new_optimizer):\n",
        "        new_optimizer_state_structure = jax.tree_structure(new_optimizer.init(self._f.params))\n",
        "        if new_optimizer_state_structure != jax.tree_structure(self.optimizer_state):\n",
        "            raise AttributeError(\"cannot set optimizer attr: mismatch in optimizer_state structure\")\n",
        "        self._optimizer = new_optimizer\n",
        "\n",
        "    @property\n",
        "    def optimizer_state(self):\n",
        "        return self._optimizer_state\n",
        "\n",
        "    @optimizer_state.setter\n",
        "    def optimizer_state(self, new_optimizer_state):\n",
        "        if jax.tree_structure(new_optimizer_state) != jax.tree_structure(self.optimizer_state):\n",
        "            raise AttributeError(\"cannot set optimizer_state attr: mismatch in tree structure\")\n",
        "        self._optimizer_state = new_optimizer_state\n",
        "\n",
        "    @property\n",
        "    def v(self):\n",
        "        return self._f\n",
        "\n",
        "    @property\n",
        "    def v_targ(self):\n",
        "        return self._f_targ \n",
        "\n",
        "    @property\n",
        "    def target_params(self):\n",
        "        return hk.data_structures.to_immutable_dict({\n",
        "            'v': self.v.params,\n",
        "            'v_targ': self.v_targ.params,\n",
        "            'reg': None,\n",
        "            'reg_hparams': None})\n",
        "\n",
        "    @property\n",
        "    def target_function_state(self):\n",
        "        return hk.data_structures.to_immutable_dict({\n",
        "            'v': self.v.function_state,\n",
        "            'v_targ': self.v_targ.function_state,\n",
        "            'reg': None})\n"
      ],
      "metadata": {
        "id": "xIeSQ44UAiGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1UUoorSSPPkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vanilla_pg = coax.policy_objectives.VanillaPG(pi, optimizer=optimizer_pi)"
      ],
      "metadata": {
        "id": "52OA5K_bPQXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple_td = CustomTDLearning(v, loss_function=coax.value_losses.mse, optimizer=optimizer_v)"
      ],
      "metadata": {
        "id": "3JEdsGrKDnoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fwIOcE_2PO-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lF_jBB7POmJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "for ep in range(1000):\n",
        "    s = env.reset()\n",
        "\n",
        "    for t in range(env.spec.max_episode_steps):\n",
        "        a = pi(s)\n",
        "        s_next, r, done, info = env.step(a)\n",
        "        if done and (t == env.spec.max_episode_steps - 1):\n",
        "            r = 1 / (1 - tracer.gamma)\n",
        "\n",
        "        tracer.add(s, a, r, done)\n",
        "        while tracer:\n",
        "            transition_batch = tracer.pop()\n",
        "            metrics_v, td_error = simple_td.update(transition_batch, return_td_error=True)\n",
        "            metrics_pi = vanilla_pg.update(transition_batch, td_error)\n",
        "            env.record_metrics(metrics_v)\n",
        "            env.record_metrics(metrics_pi)\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "        s = s_next\n",
        "\n",
        "    # early stopping\n",
        "    if env.avg_G > env.spec.reward_threshold:\n",
        "        break"
      ],
      "metadata": {
        "id": "4cTyrtQvO5yc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2HU2dNToPSVa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}